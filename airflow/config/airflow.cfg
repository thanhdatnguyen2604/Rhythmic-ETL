[core]
executor = LocalExecutor
sql_alchemy_conn = sqlite:////opt/airflow/airflow.db
parallelism = 4
dag_concurrency = 2
max_active_runs_per_dag = 1
load_examples = False
dags_folder = /opt/airflow/dags
logging_level = WARNING
print_stats_interval = 300

[scheduler]
child_process_log_directory = /opt/airflow/logs/scheduler
scheduler_heartbeat_sec = 10
min_file_process_interval = 60
dag_dir_list_interval = 120
num_runs = 1
processor_poll_interval = 10
job_heartbeat_sec = 30

[webserver]
web_server_worker_timeout = 120
worker_refresh_interval = 900
workers = 1
web_server_port = 8080
access_logfile = -
error_logfile = -
expose_config = False
enable_proxy_fix = False

[logging]
base_log_folder = /opt/airflow/logs
logging_level = WARNING
fab_logging_level = WARNING
log_format = %(asctime)s - %(name)s - %(levelname)s - %(message)s
log_rotation = True
log_size = 5242880
log_filename_template = {{ ti.dag_id }}/{{ ti.task_id }}/{{ execution_date.strftime('%Y-%m-%d_%H:%M:%S') }}.log

[email]
email_backend = airflow.utils.email.send_email_smtp

[smtp]
smtp_host = localhost
smtp_starttls = True
smtp_ssl = False
smtp_user = airflow
smtp_password = airflow
smtp_port = 25
smtp_mail_from = airflow@example.com

[secrets]
backend =

[api]
auth_backend = airflow.api.auth.backend.basic_auth 